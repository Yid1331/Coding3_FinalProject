{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"“Stylegan2-ada Custom Training.ipynb”","private_outputs":true,"provenance":[{"file_id":"https://github.com/ArthurFDLR/GANightSky/blob/main/GANightSky.ipynb","timestamp":1655330788671}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"5YcUMPQp6ipP"},"source":["## Install StyleGAN2-ADA on your Google Drive"]},{"cell_type":"code","metadata":{"id":"iKYAU7Wub3WW"},"source":["%tensorflow_version 1.x\n","!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"19_1uXab3gND"},"source":["Then, mount your Drive to the Colab notebook: "]},{"cell_type":"code","metadata":{"id":"pxxYlEKI9Gis"},"source":["from google.colab import drive\n","from pathlib import Path\n","\n","content_path = Path('/').absolute() / 'content'\n","drive_path = content_path / 'drive'\n","drive.mount(str(drive_path))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"epV6TDzAjox1"},"source":["Finally, run this cell to install StyleGAN2-ADA on your Drive. If you’ve already installed the repository, it will skip the installation process and only check for updates. If you haven’t installed it, it will install all the necessary files. Beside, **in**, **out**, **datasets** and **training** folders are generated for data storage. Everything will be available on your Google Drive in the folder **StyleGAN2-ADA** even after closing this Notebook."]},{"cell_type":"code","metadata":{"id":"8HX77jscX2zV"},"source":["stylegan2_repo_url  = 'https://github.com/dvschultz/stylegan2-ada' # or https://github.com/NVlabs/stylegan2-ada\n","project_path        = drive_path / 'MyDrive' / 'StyleGAN2-ADA'\n","stylegan2_repo_path = project_path / 'stylegan2-ada'\n","\n","# Create project folder if inexistant\n","if not project_path.is_dir():\n","    %mkdir \"{project_path}\"\n","%cd \"{project_path}\"\n","\n","for dir in ['in', 'out', 'datasets', 'training']:\n","    if not (project_path / dir).is_dir():\n","        %mkdir {dir}\n","if not (project_path / 'datasets' / 'source').is_dir():\n","    %mkdir \"{project_path / 'datasets' / 'source'}\"\n","\n","# Download StyleGAN2-ada\n","!git config --global user.name \"GANightSky\"\n","!git config --global user.email \"NightSky@gan.com\"\n","if stylegan2_repo_path.is_dir():\n","    !git -C \"{stylegan2_repo_path}\" fetch origin\n","    !git -C \"{stylegan2_repo_path}\" checkout origin/main -- *.py\n","else:\n","    print(\"Install StyleGAN2-ADA\")\n","    !git clone {stylegan2_repo_url}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ti11YiPAiQpb"},"source":["## Train a custom model"]},{"cell_type":"markdown","metadata":{"id":"ioqYi9NzkUfG"},"source":["Once you have installed StyleGAN2-ADA on your Google Drive and set up the working directory, you can upload your training dataset images in the associated folder."]},{"cell_type":"code","metadata":{"id":"OlV5HIEqiZvu"},"source":["dataset_name = 'briefcase'\n","datasets_source_path = project_path / 'datasets' / 'source' / (dataset_name + '.zip')\n","if datasets_source_path.is_file():\n","    print(\"Dataset ready for import.\")\n","else:\n","    print('Upload your images dataset as {}'.format(datasets_source_path))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-y1-tvr5617d"},"source":["Unfortunately, large datasets might exceed the Google Drive quota after a few training batches. Indeed, StyleGAN2 download datasets multiple times during training. You might have to import your dataset in the local storage session. However, large files cannot be copy/paste from Drive *(Input/Output error)*. \n","\n","Run this cell to download your zipped dataset from your Drive and unzip it in the local session."]},{"cell_type":"code","metadata":{"id":"eQZGo4g5y7rh"},"source":["local_dataset_path = content_path / 'drive/MyDrive/StyleGAN2-ADA/datasets/source'\n","if not local_dataset_path.is_dir():\n","    print(\"Importing dataset...\")\n","    %mkdir \"{local_dataset_path}\"\n","    %cp -a \"{project_path / 'datasets' / 'source' / (dataset_name + '.zip')}\" \"{local_dataset_path}\"\n","    print(\"Zip file succesfuly imported\")\n","else:\n","    print('Zip file allready imported')\n","\n","import zipfile\n","with zipfile.ZipFile(str(local_dataset_path / (dataset_name + '.zip')), 'r') as zip_ref:\n","    zip_ref.extractall(str(local_dataset_path))\n","print('Extraction completed')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeS9tDvt61VG"},"source":["### Convert dataset to .tfrecords"]},{"cell_type":"markdown","metadata":{"id":"_Q58MJbckLUc"},"source":["Next, we need to convert our image dataset to a format that StyleGAN2-ADA can read:`.tfrecords`.\n","\n","This can take a while."]},{"cell_type":"code","metadata":{"id":"IjH8kBDo3kFP"},"source":["local_images_path = local_dataset_path/'images'\n","local_dataset_path /= 'tfr'\n","\n","if (local_dataset_path).is_dir():\n","    print('\\N{Heavy Exclamation Mark Symbol} Dataset already created \\N{Heavy Exclamation Mark Symbol}')\n","    print('Delete current dataset folder ({}) to regenerate tfrecords.'.format(local_dataset_path))\n","else:\n","    %mkdir \"{local_dataset_path}\"\n","    !python \"{stylegan2_repo_path / 'dataset_tool.py'}\" create_from_images \\\n","        \"{local_dataset_path}\" \"{local_images_path}\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8DvTupHzP2s_"},"source":["There are numerous arguments to tune the training of your model. To obtain nice results, you will certainly have to experiment. Here are the most popular parameters:\n","\n","\n","*   *mirror:* Should the images be mirrored vertically?\n","*   *mirrory:* Should the images be mirrored horizontally?\n","*   *snap:* How often should the model generate image samples and a network pickle (.pkl file)?\n","*   *resume:* Network pickle to resume training from?\n","\n","To see all the options, run the following ```help``` cell.\n","\n","Please note that Google Colab Pro gives access to V100 GPUs, which drastically decreases (~3x) processing time over P100 GPUs."]},{"cell_type":"code","metadata":{"id":"Fxu7CA0Qb1Yd"},"source":["!python \"{stylegan2_repo_path / 'train.py'}\" --help"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install -U numpy==1.18.5"],"metadata":{"id":"7Fsfc9zP1cs5"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOftFoyiDU3s"},"source":["training_path = project_path / 'training' / dataset_name\n","if not training_path.is_dir():\n","    %mkdir \"{training_path}\"\n","\n","#how often should the model generate samples and a .pkl file\n","snapshot_count = 2\n","#should the images be mirrored left to right?\n","mirrored = True\n","#should the images be mirrored top to bottom?\n","mirroredY = False\n","#metrics? \n","metric_list = None\n","#augments\n","augs = 'bgc'\n","\n","resume_from = 'ffhq512'\n","\n","!python \"{stylegan2_repo_path / 'train.py'}\" --outdir=\"{training_path}\" \\\n","    --data=\"{local_dataset_path}\" --resume=\"{resume_from}\" \\\n","    --snap={snapshot_count} --augpipe={augs} \\\n","    --mirror={mirrored} --mirrory={mirroredY} \\\n","    --metrics={metric_list} #--dry-run"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0A9ZNtferpk"},"source":["## Generate images from pre-trained model\n"]},{"cell_type":"code","metadata":{"id":"xnlrb9QzgaGp"},"source":["%pip install opensimplex\n","!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images --help "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQqYjeRsfYD2"},"source":["from numpy import random\n","seed_init = random.randint(10000)\n","nbr_images = 6\n","\n","generation_from = '/content/drive/MyDrive/StyleGAN2-ADA/training/briefcase/00000-tfr-mirror-auto1-bgc-resumeffhq512/network-snapshot-000024.pkl'\n","\n","!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images \\\n","    --outdir=\"{project_path / 'out'}\" --trunc=0.7 \\\n","    --seeds={seed_init}-{seed_init+nbr_images-1} --create-grid \\\n","    --network={generation_from}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5yG1UyHXXqsO"},"source":["## Latent space exploration"]},{"cell_type":"markdown","metadata":{"id":"kYLhEFGMtJIw"},"source":["It is also possible to explore the latent space associated with our model and [generate videos like this one](https://youtu.be/dcb4Ckpkx2o).\n"]},{"cell_type":"code","metadata":{"id":"veceGR6QYA93"},"source":["%pip install opensimplex\n","!python \"{stylegan2_repo_path / 'generate.py'}\" generate-latent-walk --help "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Explore through multiple seeds"],"metadata":{"id":"ZPyzMOsti14X"}},{"cell_type":"code","metadata":{"id":"UjsN05ksZYZ7"},"source":["from numpy import random\n","walk_types = ['line', 'sphere']\n","latent_walk_path = project_path / 'out' / 'latent_walk'\n","if not latent_walk_path.is_dir():\n","    %mkdir \"{latent_walk_path}\"\n","\n","explored_network = '/content/drive/MyDrive/StyleGAN2-ADA/training/briefcase/00000-tfr-mirror-auto1-bgc-resumeffhq512/network-snapshot-000024.pkl'\n","\n","seeds = [random.randint(10000) for i in range(3)]\n","print(\"Base seeds:\", seeds)\n","!python \"{stylegan2_repo_path / 'generate.py'}\" generate-latent-walk --network=\"{explored_network}\" \\\n","    --outdir=\"{latent_walk_path}\" --trunc=0.5 --walk-type=\"{walk_types[0]}\" \\\n","    --seeds={','.join(map(str, seeds))} --frames {len(seeds)*100}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Explore around a single seed"],"metadata":{"id":"OzFpkE7ZjAm3"}},{"cell_type":"code","source":["from numpy import random\n","walk_types = ['noiseloop', 'circularloop']\n","\n","latent_walk_path = project_path / 'out' / 'latent_walk'\n","if not latent_walk_path.is_dir():\n","    %mkdir \"{latent_walk_path}\"\n","\n","explored_network = 'ffhq1024'\n","\n","start_seed = random.randint(10000)\n","\n","!python \"{stylegan2_repo_path / 'generate.py'}\" generate-latent-walk --network=\"{explored_network}\" \\\n","    --outdir=\"{latent_walk_path}\" --trunc=0.4 --walk-type==\"{walk_types[1]}\" \\\n","    --start_seed=\"{start_seed}\" --diameter=20 --frames {24*5}"],"metadata":{"id":"xuGWYW1bi_W7"},"execution_count":null,"outputs":[]}]}