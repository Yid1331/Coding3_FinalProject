# Coding3_FinalProject
Name: Xiaoyi Dong

Student ID: 21035114

## 01 Project Overview
The project name is Time Tunnel, which aims to use the relevant knowledge and tools of machine learning (image generation of the **StylGAN2** model and the application of **interactML**) to carry out a creative work.

During my study of machine learning, I found that the images generated by the StyleGAN2 will go through a process from abstract to concrete. This is very similar to the physical representation of memory in my mind. So I want to use **StyleGAN2** to generate representative items representing different stages of life. Then put these “memory fragments” into the time tunnel to bring people's memories.

After that, I used **interactML** to train the position of the lens, so that the "memory fragments" can be flickered in the time tunnel, and the lights in the time tunnel will also change color with the change of the lens position.

[Video Link](https://www.youtube.com/watch?v=AfnSIu_WJmI)

![Screenshot_6](https://user-images.githubusercontent.com/81423727/174595155-685156a5-6cd0-4780-9bed-f3beb8985496.png)


## 02 Design and Development Processes

### 1.Select, download, process datasets
I chose five different stages in person's life, childhood, adolescence, youth, middle age, and old age.The corresponding representative items are Ferrari Lego toys, books, briefcases, wedding dresses, and clocks. After that, I used [Jeff Heaton](https://www.youtube.com/watch?v=9sBQqlTtQ2k)'s method to download 5 sets of 512 * 512 px images representing items on the [flickr](https://www.flickr.com/) website, each set of 200 images. After that, the obviously incorrect pictures are deleted, and the following 5 sets of data sets are formed.

![dataset](https://user-images.githubusercontent.com/81423727/174593552-774e7a0e-3c0f-4277-9be6-f525ae2175c1.jpg)

### 2.Train Dataseet

**StyleGAN2** is more in line with the effect of the image transform I want to generate. And he can generate higher resolution images. I chose the [StyleGAN2](https://colab.research.google.com/drive/1_fenx2FKJAHEPmg-ceBdxEY2TsesnTq-) model to train my datasets.Each set of data was trained for about three hours.After training, I used this model to generate the 5 representative objects and images I wanted.

![Screenshot_7](https://user-images.githubusercontent.com/81423727/174599050-fbc09697-6f05-46c7-b9ca-21fd5a796fe0.png)

#### Training Process (Take the briefcase as an example)

![case](https://user-images.githubusercontent.com/81423727/174598742-3ee5ba42-4507-46bd-a85a-d7899bc6e80b.jpg)

https://user-images.githubusercontent.com/81423727/174599300-371d5f1f-3628-43e2-ba06-22d7fa505d2a.mp4

https://user-images.githubusercontent.com/81423727/174599346-13b20528-ef49-40a5-aa9b-288efed7287b.mp4

https://user-images.githubusercontent.com/81423727/174599399-ae82b4dc-d14a-4b04-9239-6bc18f73e786.mp4

https://user-images.githubusercontent.com/81423727/174599433-6f3da7e6-487a-4ea9-8f55-a4b94d1b29a3.mp4

https://user-images.githubusercontent.com/81423727/174599473-8929881e-3f70-421b-915a-c4e358f56f1e.mp4


### 3.Modeling

After that I used C4D to model the tunnel.

![Screenshot_8](https://user-images.githubusercontent.com/81423727/174600749-7bce1e32-bbeb-4341-b76d-d5a5279f0ca0.png)


### 4.Import models and videos into UE4

![unreal](https://user-images.githubusercontent.com/81423727/174603838-fe3c84d9-80ba-4ef5-ad3c-26596df20c31.jpg)

### 5.Training camera positions

Use interactML to train camera positions, control video transparency, and tunnel lights.

![train](https://user-images.githubusercontent.com/81423727/174607304-676f832f-0b7a-4636-85b8-a44f7d607ff6.jpg)

[Training Location Video](https://www.youtube.com/watch?v=egJb-_nrVCE)

![Screenshot_14](https://user-images.githubusercontent.com/81423727/174607432-fcbedc86-981d-43f7-a9e3-70f59345b589.png)



## 03 Evaluation

In the process of training the dataset, I found that the choice of the dataset has a great influence on the training results. For example, when I was training a LEGO Ferrari image set,the color difference of the generated image is very large, and the content of the image cannot be recognized at all. After that, I filtered the pictures in the dataset to make the content features of the pictures more obvious, and finally generated a fairly good image.

I had hoped that the resulting image would have more varied image variations, but the final result didn't work out. This may be because when I process the dataset, the features of the images are too obvious, and the number of images in the dataset is too small. I will make improvements to this issue later.


## 04 Reference

#### Datasets: 

https://drive.google.com/drive/folders/1Y0_d24zOXLASBDt9axQDGZilY9l8bE3b


#### Code github link: 


StyleGAN2 : https://github.com/dvschultz/stylegan2-ada

Train datasets: https://colab.research.google.com/drive/1_fenx2FKJAHEPmg-ceBdxEY2TsesnTq-#scrollTo=pxxYlEKI9Gis

Download and resize images: https://github.com/jeffheaton/pyimgdata


#### InteractML:

https://github.com/Interactml/iml-ue4


#### Texture Resource:

https://www.patreon.com/posts/45516670
